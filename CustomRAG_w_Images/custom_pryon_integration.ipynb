{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4df150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESIRED FORMAT: Provide a detailed answer in a concise format.\n",
      "QUERY: Minimum LDL-C or non-HDL cholesterol level for Repatha efficacy optimization.\n",
      "LANGUAGE: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum total API Exchange latency: 2.402 seconds\n",
      "Overall runtime for this dataset: 2.402 seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "For patients at very high risk of ASCVD, particularly those who have experienced a recent myocardial infarction (MI), the minimum baseline for initiating treatment with a PCSK9 inhibitor like Repatha® to optimize efficacy is an LDL-C level of 70 mg/dL or greater, or a non-high density lipoprotein cholesterol (non-HDL-C) level of 100 mg/dL or greater[2][3]. Adding a PCSK9 inhibitor is recommended after maximizing statin therapy, possibly in combination with ezetimibe[3]. This approach is supported by guidelines aimed at reducing future cardiovascular risk and improving patient outcomes after an acute coronary syndrome event[2][3]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 1:  amgen-s3-gco-document-search/General/field_rep_ai/Repatha Mod3_Dyslipidaemia.pdf\n",
      "Source 2:  amgen-s3-gco-document-search/General/field_rep_ai/Recent MI 1 year JAMA.pdf\n",
      "Source 3:  amgen-s3-gco-document-search/General/field_rep_ai/Latest FOURIER sub-analysis Recent MI.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests, json, os, csv, argparse, time\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from google.cloud import storage\n",
    "from config import ENVIRONMENT, KD_ID, CLIENT_ID, CLIENT_SECRET, MAX_OUTPUTS, AUTH_URL, EXCHANGE_ENDPOINT, API_BASE_URL\n",
    "import image_functions as imgf\n",
    "import json\n",
    "from io import BytesIO\n",
    "import askGPT as ask_gpt\n",
    "import re\n",
    "import threading\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "query = \"What is the minimum baseline for LDL-C or non-high density lipoprotein cholesterol level to optimize efficacy of Repatha?\"\n",
    "df_in = pd.DataFrame({\"Question\": [query]})\n",
    "\n",
    "def replace_with_links(text, urls):\n",
    "    # Regular expression to find the numbered references\n",
    "    pattern = r\"\\[(\\d+)\\]\"\n",
    "    \n",
    "    # Replacement function\n",
    "    def repl(match):\n",
    "        number = match.group(1)  # Extract the number from the match\n",
    "        url = urls.get(number, \"#\")  # Get the URL for the number, default to \"#\" if not found\n",
    "        return f'<a href=\"{url}\" target=\"_blank\" style=\"font-size: 10px;\">{number}</a>'  # Return the HTML link\n",
    "    \n",
    "    # Replace all occurrences in the text\n",
    "    return re.sub(pattern, repl, text)    \n",
    "\n",
    "def send_to_another_webhook(query):\n",
    "    # Define the URL of the second webhook\n",
    "    second_webhook_url = 'https://us-east4-dto-pryon-chatbot-dkuv.cloudfunctions.net/image_call_DTO'\n",
    "\n",
    "    # Prepare the data to send\n",
    "    data = {\n",
    "        'text': query\n",
    "    }\n",
    "\n",
    "    # Make the POST request in a separate thread\n",
    "    def post_data():\n",
    "        try:\n",
    "            requests.post(second_webhook_url, json=data)\n",
    "            print(\"Data sent to the second webhook successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to send data to the second webhook: {e}\")\n",
    "\n",
    "    # Start the thread\n",
    "    thread = threading.Thread(target=post_data)\n",
    "    thread.start()\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "b =\"\"\n",
    "user_query = \"\"\"\n",
    "This is the a user query: {QUESTION} {CONTEXT}\n",
    "If the query is in a foreign language, please translate it to English before processing, and provide the language of the original query in the formation below. \n",
    "Break the query apart into \"DESIRED FORMAT:\" and \"QUERY:\" to feed into an IRQA system. I want to isolate the question for better input without any formatting instructions. \n",
    "Optimize the query for key words, related terms, or vocabulary that would be better processed by an IRQA system. Keep it in semantic language. \n",
    "If there appears to be only the query and no desired format, pass as the DESIRED FORMAT: General reply under 100 words, but comprehensive with descriptive detail in a formatted response. \n",
    "Optimize this query as much as possible for a semantic search query to an IRQA AI system. As needed, add in key words related to the query to assist in retreival of relevant information\n",
    "If you determine the query is chit-chat in nature, in the sense that it is not requesting information is making comments, etc, simply pass the original query into QUERY: with a (chit-chat) label appended to the end \n",
    "\n",
    "The DESIRED FORMAT should be what you infer the format of the response the user is requesting, this should be in sentence form. Desired format should never reference the subject \n",
    "or material in the question. It is a general instruction.\n",
    "\n",
    "Only give me this in your reply:\n",
    "\n",
    "DESIRED FORMAT: (insert what you infer are the formatting instructions)\n",
    "QUERY: (optimized query here)\n",
    "LANGUAGE: (language of the original query)\n",
    "\n",
    "EXAMPLE 1:\n",
    "\n",
    "\"Write me a story about dogs\"\n",
    "\n",
    "DESIRED FORMAT: Write the output as a story\n",
    "QUERY: What can you tell me about dogs\n",
    "LANGUAGE: English\n",
    "\n",
    "EXAMPLE 2:\n",
    "\"What is the best breed of dogs, give me a list\"\n",
    "\n",
    "INSTRUCTIONS: Write the output as a list\n",
    "QUERY: What are the best breeds of dogs\n",
    "LANGUAGE: English\n",
    "\"\"\"\n",
    "\n",
    "reply = ask_gpt.askGPT(query,\"\",user_query)\n",
    "print(reply)\n",
    "\n",
    "# Using regular expressions to find matches for DESIRED FORMAT and QUERY\n",
    "d_format_match = re.search(r\"DESIRED FORMAT: (.*)\", reply)\n",
    "query_match = re.search(r\"QUERY: (.*)\", reply)\n",
    "language = re.search(r\"LANGUAGE: (.*)\", reply)\n",
    "\n",
    "# Extracting the matched groups if they are found\n",
    "d_format = d_format_match.group(1).strip() if d_format_match else \"\"\n",
    "query_new = query_match.group(1).strip() if query_match else \"\"\n",
    "language = language.group(1).strip() if language else \"\"\n",
    "\n",
    "\n",
    "\n",
    "df_in = pd.DataFrame({\"Question\": [query_new]})\n",
    "\n",
    "df_exchange, access_token = imgf.LeoE2E(df_in)\n",
    "# Assuming df_exchange is your DataFrame\n",
    "\n",
    "\n",
    "answer = str(df_exchange.get('best_1_text', default=pd.Series([None]))[0])\n",
    "\n",
    "source1_title = str(df_exchange.get('best_1_content_display_name', pd.Series([None])).iloc[0])\n",
    "source2_title = str(df_exchange.get('best_2_content_display_name', pd.Series([None])).iloc[0])\n",
    "source3_title = str(df_exchange.get('best_3_content_display_name', pd.Series([None])).iloc[0])\n",
    "source4_title = str(df_exchange.get('best_4_content_display_name', pd.Series([None])).iloc[0])\n",
    "source5_title = str(df_exchange.get('best_5_content_display_name', pd.Series([None])).iloc[0])\n",
    "\n",
    "\n",
    "contextans = str(df_exchange.get('best_1_aic', pd.Series([None])).iloc[0])\n",
    "contextans2 = str(df_exchange.get('best_2_aic', pd.Series([None])).iloc[0])\n",
    "contextans3 = str(df_exchange.get('best_3_aic', pd.Series([None])).iloc[0])\n",
    "contextans4 = str(df_exchange.get('best_4_aic', pd.Series([None])).iloc[0])\n",
    "contextans5 = str(df_exchange.get('best_5_aic', pd.Series([None])).iloc[0])\n",
    "\n",
    "\n",
    "conf_1_value = df_exchange.get('best_1_score', pd.Series([None])).iloc[0]\n",
    "conf_2_value = df_exchange.get('best_2_score', pd.Series([None])).iloc[0]\n",
    "conf_3_value = df_exchange.get('best_3_score', pd.Series([None])).iloc[0]\n",
    "conf_4_value = df_exchange.get('best_4_score', pd.Series([None])).iloc[0]\n",
    "conf_5_value = df_exchange.get('best_5_score', pd.Series([None])).iloc[0]\n",
    "\n",
    "conf_1 = float(conf_1_value) if conf_1_value is not None else None\n",
    "conf_2 = float(conf_2_value) if conf_2_value is not None else None\n",
    "conf_3 = float(conf_3_value) if conf_3_value is not None else None\n",
    "conf_4 = float(conf_4_value) if conf_4_value is not None else None\n",
    "conf_5 = float(conf_5_value) if conf_5_value is not None else None\n",
    "\n",
    "\n",
    "URL = str(df_exchange.get('best_1_url', pd.Series([None])).iloc[0])\n",
    "URL2 = str(df_exchange.get('best_2_url', pd.Series([None])).iloc[0])\n",
    "URL3 = str(df_exchange.get('best_3_url', pd.Series([None])).iloc[0])\n",
    "URL4 = str(df_exchange.get('best_4_url', pd.Series([None])).iloc[0])\n",
    "URL5 = str(df_exchange.get('best_5_url', pd.Series([None])).iloc[0])\n",
    "\n",
    "content_id_1 = df_exchange.get('best_1_content_id', pd.Series([None])).iloc[0]\n",
    "image_page_1 = df_exchange.get('ans1_text_sentence_bbox_1_page', pd.Series([None])).iloc[0]\n",
    "\n",
    "content_id_2 = df_exchange.get('best_2_content_id', pd.Series([None])).iloc[0]\n",
    "image_page_2 = df_exchange.get('ans2_text_sentence_bbox_1_page', pd.Series([None])).iloc[0]\n",
    "\n",
    "content_id_3 = df_exchange.get('best_3_content_id', pd.Series([None])).iloc[0]\n",
    "image_page_3 = df_exchange.get('ans3_text_sentence_bbox_1_page', pd.Series([None])).iloc[0]\n",
    "\n",
    "content_id_4 = df_exchange.get('best_4_content_id', pd.Series([None])).iloc[0]\n",
    "image_page_4 = df_exchange.get('ans4_text_sentence_bbox_1_page', pd.Series([None])).iloc[0]\n",
    "\n",
    "content_id_5 = df_exchange.get('best_5_content_id', pd.Series([None])).iloc[0]\n",
    "image_page_5 = df_exchange.get('ans5_text_sentence_bbox_1_page', pd.Series([None])).iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "page1 = image_page_1\n",
    "page2 = image_page_2\n",
    "page3 = image_page_3\n",
    "page4 = image_page_4\n",
    "page5 = image_page_5\n",
    "\n",
    "# Append page number to URL if it's a PDF\n",
    "if URL.endswith('.pdf'):\n",
    "    Source1 = f\"{URL}#page={page1}\"\n",
    "else:\n",
    "    Source1 = URL\n",
    "\n",
    "# Append page number to URL2 if it's a PDF\n",
    "if URL2.endswith('.pdf'):\n",
    "    Source2 = f\"{URL2}#page={page2}\"\n",
    "else:\n",
    "    Source2 = URL2\n",
    "\n",
    "# Append page number to URL3 if it's a PDF\n",
    "if URL3.endswith('.pdf'):\n",
    "    Source3 = f\"{URL3}#page={page3}\"\n",
    "else:\n",
    "    Source3 = URL3\n",
    "\n",
    "# Append page number to URL4 if it's a PDF\n",
    "if URL4.endswith('.pdf'):\n",
    "    Source4 = f\"{URL4}#page={page4}\"\n",
    "else:\n",
    "    Source4 = URL4\n",
    "\n",
    "# Append page number to URL5 if it's a PDF\n",
    "if URL5.endswith('.pdf'):\n",
    "    Source5 = f\"{URL5}#page={page5}\"\n",
    "else:\n",
    "    Source5 = URL5\n",
    "\n",
    "# Create image URLs based on the query if the source URLs are PDFs\n",
    "query_letters_only = ''.join([char for char in query if char.isalpha()])\n",
    "\n",
    "if URL.endswith('.pdf'):\n",
    "    URL = f'https://storage.googleapis.com/dto_pryon_images/{query_letters_only}1.png'\n",
    "else:\n",
    "    URL = URL\n",
    "\n",
    "if URL2.endswith('.pdf'):\n",
    "    URL2 = f'https://storage.googleapis.com/dto_pryon_images/{query_letters_only}2.png'\n",
    "else:\n",
    "    URL2 = URL2\n",
    "\n",
    "if URL3.endswith('.pdf'):\n",
    "    URL3 = f'https://storage.googleapis.com/dto_pryon_images/{query_letters_only}3.png'\n",
    "else:\n",
    "    URL3 = URL3\n",
    "\n",
    "if URL4.endswith('.pdf'):\n",
    "    URL4 = f'https://storage.googleapis.com/dto_pryon_images/{query_letters_only}4.png'\n",
    "else:\n",
    "    URL4 = URL4\n",
    "\n",
    "if URL5.endswith('.pdf'):\n",
    "    URL5 = f'https://storage.googleapis.com/dto_pryon_images/{query_letters_only}5.png'\n",
    "else:\n",
    "    URL5 = URL5\n",
    "\n",
    "# Dictionary of URLs\n",
    "urls = {\n",
    "    \"1\": URL,\n",
    "    \"2\": URL2,\n",
    "    \"3\": URL3,\n",
    "    \"4\": URL4,\n",
    "    \"5\": URL5,\n",
    "}\n",
    "\n",
    "\n",
    "default_prompt = (\n",
    "    f\"You are a RAG generative tool used to smooth answers from context information and you are responding to the question: {{QUESTION}}. \"\n",
    "    \"Here are 6 instructions you must follow for each response, with all responses being in a qell structured markdown format with lists, paragrah breaks, etc as approproate:\"\n",
    "    \"FIRST INSTRUCTION: If you detect the question is chit-chat, please simply follow the chit-chat guide at the end. \"\n",
    "    \"SECOND INSTRUCTION: Use only the information provided in the context below. Provide a summary response as closely as you can for the related information, IMPORTANT: Please supply supplemental information in addition to the direct answer to provide some context and furthur insights \"\n",
    "    f\"THIRD INSTRUCTION: Keep responses concise (100 words or less), and these instructions: {d_format} and in this language: {language}.\"\n",
    "    \"FOURTH INSTRUCTION: Format the response as a summary unless otherwise noted by the user. \"\n",
    "    \"FIFTH INSTRUCTION: After each sentence, if information from the context was used, append the sentence with [n] where n is the source number where the information resides, whole numbers only never use decimals: For example [1] is valid and [1.1] is invalid. Output example: Sentence one proxy data here using source 2 [1] and info used here from source 2 [2]. \"\n",
    "    \"SIXTH INSTRUCTION: If the information is not found in the context data provided, apologize to the user give a general summary of what information you do have in the context of the question \"\n",
    "    \"CONTEXT INFORMATION - USE ONLY THIS PLEASE TO FORMAT A RESPONSE. YOU ARE A RAG TOOL. DO NOT DEVIATE FROM THIS INFORMATION: \"\n",
    "    \"{{CONTEXT}}.\"\n",
    "    \"END CONTEXT INFORMATION \"\n",
    "    f\"CHIT CHAT GUIDE\"\n",
    "    \"If Chit-chat was detected, ignore all the context information above. Take on the personal of a friendly AI assistant. Try to address any of the concernst in a friendly manner\"\n",
    "    \"Do no make up any information, simple be a conversational agent with a personality of helpfulness and professionalism\")\n",
    "\n",
    "\n",
    "\n",
    "pryon_data = (\n",
    "    f\"Source 1 Information: {contextans}\\n\"\n",
    "    f\"Source 2 Information: {contextans2}\\n\"\n",
    "    f\"Source 3 Information: {contextans3}\\n\"\n",
    "    f\"Source 4 Information: {contextans4}\\n\"  # Added source 4 information\n",
    "    f\"Source 5 Information: {contextans5}\\n\"  # Added source 5 information\n",
    ")\n",
    "\n",
    "# Assuming ask_gpt.askGPT is a function call relevant in your codebase\n",
    "g_answer = ask_gpt.askGPT(query, pryon_data, default_prompt)\n",
    "\n",
    "#print(g_answer)\n",
    "\n",
    "formatted_generative = replace_with_links(g_answer, urls)\n",
    "\n",
    "sources_string = \"\"\n",
    "source_order = []\n",
    "\n",
    "# Find all occurrences of [1] to [5] and their order\n",
    "for marker in [\"[1]\", \"[2]\", \"[3]\", \"[4]\", \"[5]\"]:  # Included markers for [4] and [5]\n",
    "    if marker in g_answer:\n",
    "        source_order.append((g_answer.index(marker), marker))\n",
    "\n",
    "# Sort by order of occurrence\n",
    "source_order.sort()\n",
    "\n",
    "# Append the source links and titles to sources_string based on the occurrence of markers\n",
    "for _, marker in source_order:\n",
    "    if marker == \"[1]\":\n",
    "        sources_string += f'<a href=\"{Source1}\" target=\"_blank\" style=\"font-size: 6px;\">SOURCE 1</a><span style=\"font-size: 10px; color: grey;\">  {source1_title}</span><br>'\n",
    "    elif marker == \"[2]\":\n",
    "        sources_string += f'<a href=\"{Source2}\" target=\"_blank\" style=\"font-size: 6px;\">SOURCE 2</a><span style=\"font-size: 10px; color: grey;\">  {source2_title}</span><br>'\n",
    "    elif marker == \"[3]\":\n",
    "        sources_string += f'<a href=\"{Source3}\" target=\"_blank\" style=\"font-size: 6px;\">SOURCE 3</a><span style=\"font-size: 10px; color: grey;\">  {source3_title}</span><br>'\n",
    "    elif marker == \"[4]\":  # Handling for source 4\n",
    "        sources_string += f'<a href=\"{Source4}\" target=\"_blank\" style=\"font-size: 6px;\">SOURCE 4</a><span style=\"font-size: 10px; color: grey;\">  {source4_title}</span><br>'\n",
    "    elif marker == \"[5]\":  # Handling for source 5\n",
    "        sources_string += f'<a href=\"{Source5}\" target=\"_blank\" style=\"font-size: 6px;\">SOURCE 5</a><span style=\"font-size: 10px; color: grey;\">  {source5_title}</span><br>'\n",
    "\n",
    "# Remove the last <br> tag if sources_string is not empty\n",
    "if sources_string.endswith(\"<br>\"):\n",
    "    sources_string = sources_string[:-4]\n",
    "\n",
    "formatted_html = sources_string\n",
    "\n",
    "\n",
    "#Adding a custom OOD function here... to change response. \n",
    "if source1_title.startswith(\"VA:\"):\n",
    "    dialogflow_cx_response ={\n",
    "        \"fulfillment_response\": {\n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"text\": {\n",
    "                \"text\": [answer]\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "elif len(sources_string) < 5:\n",
    "    dialogflow_cx_response ={\n",
    "        \"fulfillment_response\": {\n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"text\": {\n",
    "                \"text\": [formatted_generative]\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    # richContent is where you can modify dialogflow messenger data. \n",
    "    dialogflow_cx_response = {\n",
    "        \"fulfillment_response\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"payload\": {\n",
    "                        \"richContent\": [[\n",
    "                                #HTML TEST\n",
    "                                {\n",
    "                                    \"type\": \"html\",\n",
    "                                    \"html\": [formatted_generative]\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"html\",\n",
    "                                    \"html\": [formatted_html]\n",
    "                                }\n",
    "                            ]\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "display(Markdown(g_answer))\n",
    "print(\"Source 1: \",source1_title)\n",
    "print(\"Source 2: \",source2_title)\n",
    "print(\"Source 3: \",source3_title)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f2e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In their position paper, the IAS identifies total risk as the sum of the \n",
       "following risk factors:43  \n",
       "\n",
       "   Elevated LDL  \n",
       "   Cigarette smoking  \n",
       "   Hypertension  \n",
       "   Diabetes  \n",
       "   Low levels of HDL-C  \n",
       "   Positive family history for ASCVD  \n",
       "\n",
       "The IAS’ position towards management of dyslipidaemia is focused on \n",
       "identification of optimal levels of atherogenic cholesterol and adjustment \n",
       "of the intensity of cholesterol-lowering therapy to long-term risk. The table \n",
       "shown here summarizes their recommendations.43  \n",
       "\n",
       "For primary prevention of ASCVD, the IAS defines optimal levels of \n",
       "atherogenic cholesterol as follows:  \n",
       "\n",
       "   LDL:  \n",
       "<100 mg/dL (2.6 mmol/L)  \n",
       "   The optimal LDL in patients with established ASCVD is <70 mg/dL.43  \n",
       "   Non–HDL-C: \n",
       "<130 mg/dL (3.4 mmol/L)  \n",
       "\n",
       "DYSLIPIDAEMIA MODULE 3 \n",
       "\n",
       "These materials are for internal training use only and are not to be shown to healthcare professionals. \n",
       "Amgen Confidential 2015. All rights reserved. EUHQ-P-145-0315-103230 \n",
       "49 \n",
       "\n",
       "CHAPTER 4: DIAGNOSIS OF DYSLIPIDAEMIA  \n",
       "AND GENERAL TREATMENT RECOMMENDATIONS \n",
       "\n",
       "IAS Recommendations for Therapy by Risk Level  \n",
       "\n",
       "TNS} for Therapy Ne Risk Level\n",
       "Risk level to 80 Low (<15%) Moderate\n",
       "years of age (15%-29%)\n",
       "Therapeutic intensity Moderate\n",
       "Specific therapy Public health MLT + CLD\n",
       "recommendation? optional?\n",
       "Moderately high High (>45%)\n",
       "(30%-44%)\n",
       "Moderately high High\n",
       "MLT + CLD MLT + CLD\n",
       "consideration® indicated*\n",
       "\n",
       "CLD = cholesterol-lowering drug, usually a statin; IAS = International Atherosclerosis Society; MLT = maximal lifestyle therapies.\n",
       "2 Persons at low risk of ASCVD should be treated according to national recommendation for the general public. These recommendations should be in accord\n",
       "with IAS recommendations for lifestyle therapies.\n",
       "© CLD therapy is usually reserved for patients with high levels of atherogenic cholesterol.\n",
       "© Statin therapy is widely recommended for this risk category, although it is not accepted in many countries because of cost considerations. If drugs are used,\n",
       "the dose should be adequate to achieve optimal atherogenic cholesterol levels.\n",
       "4 CLD therapy is usually indicated in this category. The dose should be adequate to achieve optimal atherogenic cholesterol levels."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(contextans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f1435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the 2018 American Heart Association/American\n",
       "College of Cardiology Multisociety Guideline on the Manage-\n",
       "ment of Blood Cholesterol, patients with clinical ASCVD\n",
       "are separated into 2 different subgroups: those at very high risk\n",
       "vs not.1 The management of patients at very high risk in-\n",
       "cludes a recommendation for adding a PCSK9 inhibitor\n",
       "in patients with LDL-C levels of 70 mg/dL or greater or\n",
       "non–HDL-C levels of 100 mg/dL or greater in addition to maxi-\n",
       "mally tolerated statin plus ezetimibe therapy.1 Likewise,\n",
       "the 2019 European Society of Cardiology and European\n",
       "Atherosclerosis Society guidelines for the management of\n",
       "dyslipidemias categorizes patients with MI as a very high-\n",
       "risk group and recommends both a reduction of LDL-C of\n",
       "50% or greater and an LDL-C target of less than 55 mg/dL\n",
       "(1.4 mmol/L).10\n",
       "\n",
       "Early and systematic optimization of lipid-lowering\n",
       "therapy is a validated process outcome for measurement of\n",
       "quality improvement in patients with MI.11 However, obser-\n",
       "vational studies showed that underuse of high-intensity\n",
       "lipid-lowering therapy remains a well-known gap in second-\n",
       "ary prevention.12 The present analysis from the FOURIER\n",
       "trial highlights the importance of ensuring an optimal pro-\n",
       "cess of care after hospital discharge within this critical first\n",
       "year after MI.13 In addition, the benefit of adding PCSK9 inhi-\n",
       "bition in patients with recent ACS was strengthened with\n",
       "data from the Evaluation of Cardiovascular Outcomes After\n",
       "an Acute Coronary Syndrome During Treatment With Ali-\n",
       "rocumab (ODYSSEY Outcomes) trial14 where the median\n",
       "time between the index event from the time of randomiza-\n",
       "tion was 2.6 months.\n",
       "\n",
       "Limitations\n",
       "\n",
       "Our study had limitations. We acknowledge that only 3.3% and\n",
       "6.3% of patients were treated with ezetimibe prior to random-"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(contextans2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d56f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the 2018 American Heart Association/American\n",
       "College of Cardiology Multisociety Guideline on the Manage-\n",
       "ment of Blood Cholesterol, patients with clinical ASCVD\n",
       "are separated into 2 different subgroups: those at very high risk\n",
       "vs not.1 The management of patients at very high risk in-\n",
       "cludes a recommendation for adding a PCSK9 inhibitor\n",
       "in patients with LDL-C levels of 70 mg/dL or greater or\n",
       "non–HDL-C levels of 100 mg/dL or greater in addition to maxi-\n",
       "mally tolerated statin plus ezetimibe therapy.1 Likewise,\n",
       "the 2019 European Society of Cardiology and European\n",
       "Atherosclerosis Society guidelines for the management of\n",
       "dyslipidemias categorizes patients with MI as a very high-\n",
       "risk group and recommends both a reduction of LDL-C of\n",
       "50% or greater and an LDL-C target of less than 55 mg/dL\n",
       "(1.4 mmol/L).10\n",
       "\n",
       "Early and systematic optimization of lipid-lowering\n",
       "therapy is a validated process outcome for measurement of\n",
       "quality improvement in patients with MI.11 However, obser-\n",
       "vational studies showed that underuse of high-intensity\n",
       "lipid-lowering therapy remains a well-known gap in second-\n",
       "ary prevention.12 The present analysis from the FOURIER\n",
       "trial highlights the importance of ensuring an optimal pro-\n",
       "cess of care after hospital discharge within this critical first\n",
       "year after MI.13 In addition, the benefit of adding PCSK9 inhi-\n",
       "bition in patients with recent ACS was strengthened with\n",
       "data from the Evaluation of Cardiovascular Outcomes After\n",
       "an Acute Coronary Syndrome During Treatment With Ali-\n",
       "rocumab (ODYSSEY Outcomes) trial14 where the median\n",
       "time between the index event from the time of randomiza-\n",
       "tion was 2.6 months.\n",
       "\n",
       "Limitations\n",
       "\n",
       "Our study had limitations. We acknowledge that only 3.3% and\n",
       "6.3% of patients were treated with ezetimibe prior to random-"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(contextans3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d56888",
   "metadata": {},
   "outputs": [],
   "source": [
    " #GENERATE IMAGES AND SAVE TO GOOGLE CLOUD STORAGE\n",
    "content_image_pairs = [\n",
    "    (content_id_1, image_page_1),\n",
    "    (content_id_2, image_page_2),\n",
    "    (content_id_3, image_page_3),\n",
    "    (content_id_4, image_page_4),\n",
    "    (content_id_5, image_page_5)\n",
    "]\n",
    "\n",
    "print(content_image_pairs)\n",
    "\n",
    "bucket_name = 'dto_pryon_images'  # Your bucket name\n",
    "credentials_json = 'gcp_cred.json'  # Your GCP credentials path\n",
    "query_letters_only = ''.join([char for char in query if char.isalpha()])\n",
    "\n",
    "for i, (content_id, image_page) in enumerate(content_image_pairs, start=1):\n",
    "    if image_page:\n",
    "        image = Image.open(BytesIO(imgf.get_image(access_token, content_id, image_page, uncompressed=0)))\n",
    "        image_with_highlights = imgf.highlighted_contextimage(df_exchange, image, str(i))\n",
    "        imgf.upload_to_gcp(content_id, image_with_highlights, bucket_name, credentials_json, f'{query_letters_only}{i}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
